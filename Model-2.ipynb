{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8150821,"sourceType":"datasetVersion","datasetId":4816444},{"sourceId":33328,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":27904}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\nimport torch\nimport pandas\nfrom transformers import AutoTokenizer, AutoModel\n\nfrom transformers import DistilBertModel, DistilBertTokenizer\n\n# Load pre-trained model and tokenizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nPAD = 26","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T06:53:32.845516Z","iopub.execute_input":"2024-04-18T06:53:32.846330Z","iopub.status.idle":"2024-04-18T06:53:43.355886Z","shell.execute_reply.started":"2024-04-18T06:53:32.846295Z","shell.execute_reply":"2024-04-18T06:53:43.354817Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49937b620f5e4c76aa6312336db337bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11f66854104436b9d6bd3b20d6f9dcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a65fd70afa84073bbe14f05b22d4f1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f7261703724e46b05cc75fd24e2ff5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c29e50cf9104efd8bb73ba373dc3007"}},"metadata":{}}]},{"cell_type":"code","source":"df = pandas.read_json(\"/kaggle/input/nlpaa4/train_file.json\")\ndf_val = pandas.read_json(\"/kaggle/input/nlpaa4/val_file.json\")\ndf_test = pandas.read_json(\"/kaggle/input/nlpaa4/val_file.json\")\ntorch.cuda.empty_cache()\nimport gc\nTEST = True\ndef yolo(lis):\n    f = dict()\n    ret = [0]*PAD\n    for i in range(len(lis)):\n        if lis[i] not in f.keys():\n            f[lis[i]] = len(f) + 1\n        ret[PAD - len(lis) +i] = f[ lis[i]]\n    return ret\n     \ndef solo(l):\n    f = {\n        \"surprise\": 1,\n        \"fear\": 2,\n        \"sadness\":3,\n        \"disgust\": 4,\n        \"joy\": 5,\n        \"neutral\": 6,\n        \"anger\":7\n    }\n    ret = [0]*PAD\n    for i in range(len(l)):\n        ret[PAD-len(l) + i] = f[l[i]]\n    return ret\n\ndef golo(r):\n    s = PAD - len(r)\n    ret = [\"\"]*s\n    ret.extend(r)\n    device = torch.get_current_device()\n    device.reset()\n    with torch.no_grad():\n            model.to(device)\n            encoded_input = tokenizer(ret, return_tensors='pt',padding='max_length', max_length=50, truncation=True).to(device)\n            output = model(**encoded_input)\n    return output\n\ndef tolo(r):\n    s = PAD - len(r)\n    ret = [0]*s\n    for i in r:\n        if i == None:\n            ret = None\n            break\n        ret.append(i)\n    return ret\n\ntqdm.pandas(desc=\"kefo\")\ndf[\"speakers\"] = df[\"speakers\"].progress_apply(lambda r: yolo(r))\ndf[\"emotions\"] = df[\"emotions\"].progress_apply(lambda r: solo(r))\ndf[\"triggers\"] = df[\"triggers\"].progress_apply(lambda r: tolo(r))\n# df[\"utterances\"] = df[\"utterances\"].progress_apply(lambda r: golo(r))\n\ndf_val[\"speakers\"] = df_val[\"speakers\"].progress_apply(lambda r: yolo(r))\ndf_val[\"emotions\"] = df_val[\"emotions\"].progress_apply(lambda r: solo(r))\ndf_val[\"triggers\"] = df_val[\"triggers\"].progress_apply(lambda r: tolo(r))\n# df[\"utterances\"] = df[\"utterances\"].progress_apply(lambda r: golo(r))\nif TEST:\n    df_test[\"speakers\"] = df_test[\"speakers\"].progress_apply(lambda r: yolo(r))\n    df_test[\"emotions\"] = df_test[\"emotions\"].progress_apply(lambda r: solo(r))\n    df_test[\"triggers\"] = df_test[\"triggers\"].progress_apply(lambda r: tolo(r))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:53:43.761550Z","iopub.execute_input":"2024-04-18T06:53:43.761927Z","iopub.status.idle":"2024-04-18T06:53:44.329434Z","shell.execute_reply.started":"2024-04-18T06:53:43.761894Z","shell.execute_reply":"2024-04-18T06:53:44.328194Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"kefo: 100%|██████████| 6740/6740 [00:00<00:00, 100240.80it/s]\nkefo: 100%|██████████| 6740/6740 [00:00<00:00, 111449.93it/s]\nkefo: 100%|██████████| 6740/6740 [00:00<00:00, 199115.41it/s]\nkefo: 100%|██████████| 843/843 [00:00<00:00, 95035.57it/s]\nkefo: 100%|██████████| 843/843 [00:00<00:00, 124618.41it/s]\nkefo: 100%|██████████| 843/843 [00:00<00:00, 168757.08it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"df = df.dropna().drop([\"episode\"],axis=1)\ndf_val = df_val.dropna().drop([\"episode\"],axis=1)\nif TEST:\n    df_test = df_test.dropna().drop([\"episode\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:53:44.332244Z","iopub.execute_input":"2024-04-18T06:53:44.332617Z","iopub.status.idle":"2024-04-18T06:53:44.367283Z","shell.execute_reply.started":"2024-04-18T06:53:44.332584Z","shell.execute_reply":"2024-04-18T06:53:44.366187Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:54:13.577377Z","iopub.execute_input":"2024-04-18T06:54:13.577720Z","iopub.status.idle":"2024-04-18T06:54:13.620655Z","shell.execute_reply.started":"2024-04-18T06:54:13.577695Z","shell.execute_reply":"2024-04-18T06:54:13.619630Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                               speakers  \\\n0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, ...   \n2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n...                                                 ...   \n6735  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6736  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6737  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6738  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6739  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                               emotions  \\\n0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 7, 3, ...   \n2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n...                                                 ...   \n6735  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6736  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6737  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6738  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6739  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                             utterances  \\\n0     [You-you\nyou had sex with Ursula?!, Uh, a litt...   \n1     [Dad, please don't pick your teeth out here!, ...   \n2     [Dr. Geller, there's a seat over here., Thank ...   \n3     [So, how'd the lasagne go over?, Really?!, Good.]   \n4     [Become a drama critic!, I am hurt!  A plague ...   \n...                                                 ...   \n6735  [I mean, I realize that his feelings may never...   \n6736  [Okay. Just give us a second. Ross!, Yeah?, Gi...   \n6737  [Did you just flick me?, OK, well, you wouldn'...   \n6738  [Oh!, Look at Emma!, I just cant decide who s...   \n6739  [Can you believe what a jerk Ross was being?, ...   \n\n                                               triggers  \n0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0....  \n2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n...                                                 ...  \n6735  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n6736  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n6737  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n6738  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n6739  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n\n[6725 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speakers</th>\n      <th>emotions</th>\n      <th>utterances</th>\n      <th>triggers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[You-youyou had sex with Ursula?!, Uh, a litt...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 7, 3, ...</td>\n      <td>[Dad, please don't pick your teeth out here!, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[Dr. Geller, there's a seat over here., Thank ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[So, how'd the lasagne go over?, Really?!, Good.]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[Become a drama critic!, I am hurt!  A plague ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6735</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[I mean, I realize that his feelings may never...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>6736</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[Okay. Just give us a second. Ross!, Yeah?, Gi...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>6737</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[Did you just flick me?, OK, well, you wouldn'...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>6738</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[Oh!, Look at Emma!, I just cant decide who s...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>6739</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[Can you believe what a jerk Ross was being?, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6725 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport pandas as pd\nchache = []\nclass CDataset(Dataset):\n    def __init__(self, data) -> None:\n        data = data\n        self.speaker = data[\"speakers\"]\n        self.emotions = data[\"emotions\"]\n        self.utterances = data[\"utterances\"]\n        self.triggers = data[\"triggers\"]\n    \n    def __len__(self):\n        return len(self.speaker)\n    \n    def __getitem__(self,idx):\n        global chache\n        torch.cuda.empty_cache()\n        r = self.utterances.iloc[idx]\n        s = PAD - len(r)\n        ret = [\"\"]*s\n        ret.extend(r)\n        encoded_input = tokenizer(ret, padding='max_length',truncation=True, max_length=30, return_tensors='pt').to(device)\n#         print(\"ei\")\n  \n        with torch.no_grad():\n            output = bert_model(**encoded_input)\n#             print(\"eo\")\n        cls_token_representation = output.last_hidden_state[:, 0, :]\n#         print(\"cls\")\n\n        del output\n        del chache\n        chache = [self.speaker.iloc[idx], \\\n            self.emotions.iloc[idx], \\\n            cls_token_representation, \\\n            self.triggers.iloc[idx]\n                 ]\n        return torch.tensor(self.speaker.iloc[idx],dtype=torch.float32).to(device), \\\n            torch.tensor(self.emotions.iloc[idx],dtype=torch.float32).to(device), \\\n            cls_token_representation, \\\n            torch.tensor(self.triggers.iloc[idx],dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:54:35.785512Z","iopub.execute_input":"2024-04-18T06:54:35.786288Z","iopub.status.idle":"2024-04-18T06:54:35.798888Z","shell.execute_reply.started":"2024-04-18T06:54:35.786256Z","shell.execute_reply":"2024-04-18T06:54:35.797862Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nBATCH_SIZE = 64\n\ntrain_dataloader = DataLoader(CDataset(df), batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(CDataset(df_val), batch_size=BATCH_SIZE, shuffle=True)\nif TEST:\n    test_dataloader = DataLoader(CDataset(df_test), batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:54:38.986588Z","iopub.execute_input":"2024-04-18T06:54:38.987293Z","iopub.status.idle":"2024-04-18T06:54:38.994125Z","shell.execute_reply.started":"2024-04-18T06:54:38.987261Z","shell.execute_reply":"2024-04-18T06:54:38.992977Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nclass EFR_Model(nn.Module):\n    def __init__(self):\n        super(EFR_Model, self).__init__()\n        self.hidden_size  = 150\n        self.num_layers = 1\n        \n        self.gru_speech = nn.GRU(768, self.hidden_size, self.num_layers, batch_first=True)\n        self.gru_speaker = nn.GRU(1, self.hidden_size, self.num_layers, batch_first=True)\n        self.gru_emo = nn.GRU(1, self.hidden_size, self.num_layers, batch_first=True)\n        self.fc1 = nn.Linear(3*self.hidden_size,2)\n        self.softmax = nn.Linear(2,1)\n        self.tanh = nn.Tanh()\n        \n    def forward(self, x):     \n        out1,_ = self.gru_speech(x[2])\n        out2,_ = self.gru_speaker(torch.reshape(x[0],(x[0].shape[0],x[0].shape[1],1)))\n        out3,_ = self.gru_emo(torch.reshape(x[1],(x[1].shape[0],x[1].shape[1],1)))\n#         print(.shape,\"should be (batchsize, 450)\")\n        out =self.tanh(self.softmax(self.fc1(torch.cat((out1,out2,out3),2))))\n\n        return out\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:54:41.755594Z","iopub.execute_input":"2024-04-18T06:54:41.756359Z","iopub.status.idle":"2024-04-18T06:54:41.767515Z","shell.execute_reply.started":"2024-04-18T06:54:41.756321Z","shell.execute_reply":"2024-04-18T06:54:41.766365Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = EFR_Model().to(device)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:54:45.028778Z","iopub.execute_input":"2024-04-18T06:54:45.029174Z","iopub.status.idle":"2024-04-18T06:54:45.145281Z","shell.execute_reply.started":"2024-04-18T06:54:45.029141Z","shell.execute_reply":"2024-04-18T06:54:45.144382Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!pip install torcheval\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:54:47.143298Z","iopub.execute_input":"2024-04-18T06:54:47.143768Z","iopub.status.idle":"2024-04-18T06:55:02.200623Z","shell.execute_reply.started":"2024-04-18T06:54:47.143732Z","shell.execute_reply":"2024-04-18T06:55:02.199309Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"#training\nfrom torcheval.metrics.functional import binary_f1_score, binary_accuracy\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    losses = 0\n    f1 = 0\n    a  = 0\n    for x in tqdm(dataloader):\n        # Compute prediction and loss\n        pred = model(x)\n        true = x[3].to(device)\n\n        true = torch.reshape(true,(true.shape[0],true.shape[1],1))\n        loss = loss_fn(pred,true)\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        X = torch.flatten(pred)\n        Y = torch.flatten(true)\n        f1 +=  binary_f1_score(X,Y).cpu() * true.shape[0]\n        a +=  binary_accuracy(X,Y).cpu() * true.shape[0]\n        losses += loss.item() * true.shape[0]\n    return losses/size, f1/size, a/size\n    \n\n    \ndef validation_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n#     print(size)\n    model.eval()\n    losses = 0\n    f1 = 0\n    a = 0\n    for x in tqdm(dataloader):\n        # Compute prediction and loss\n        with torch.no_grad():\n            pred = model(x)\n            true= x[3].to(device)\n            true = torch.reshape(true,(true.shape[0],true.shape[1],1))\n            loss = loss_fn(pred,true)\n            X = torch.flatten(pred)\n            Y = torch.flatten(true)\n            f1 +=  binary_f1_score(X,Y).cpu() * true.shape[0]\n            a +=  binary_accuracy(X,Y).cpu() * true.shape[0]\n            \n        losses+= loss.item() * true.shape[0]\n    return losses/size, f1/size, a/size\n\ndef test_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.eval()\n    losses = 0\n    f1 = 0\n    a = 0\n    pred = []\n    true = []\n    for x in tqdm(dataloader):\n        with torch.no_grad():\n            pred.append(np.array(model(x).cpu() > 0.5, dtype=int))\n            tr = x[3].to(device)\n            true.append(np.array(torch.reshape(tr,(tr.shape[0],tr.shape[1],1)).cpu()))\n    return pred, true\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:55:02.203162Z","iopub.execute_input":"2024-04-18T06:55:02.203489Z","iopub.status.idle":"2024-04-18T06:55:03.162504Z","shell.execute_reply.started":"2024-04-18T06:55:02.203460Z","shell.execute_reply":"2024-04-18T06:55:03.161333Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/working/m1.pt\"\nt_loss = []\nv_loss = []\nt_f = []\nv_f = []\nt_a = []\nv_a = []\nm_t = 9999\nv_t = 9999\nfor t in range(10):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    l, f,a = train_loop(train_dataloader, model, loss_fn, optimizer)\n    t_loss.append(l)\n    t_f.append(f)\n    t_a.append(a)\n    l, f,a = validation_loop(val_dataloader, model, loss_fn, optimizer)\n    v_loss.append(l)\n    v_f.append(f)\n    v_a.append(a)\n    print(f\"training loss: {t_loss[-1]}, val loss: {v_loss[-1]}, training f1: {t_f[-1]}, val f1: {v_f[-1]}, , training acc: {t_a[-1]}, val acc: {v_a[-1]}\")\n    if t_loss[-1] < m_t:\n        m_t = t_loss[-1]\n        torch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T06:55:03.163777Z","iopub.execute_input":"2024-04-18T06:55:03.164100Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▋  | 81/106 [02:26<00:45,  1.83s/it]","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(t_loss)\nplt.plot(v_loss)\nplt.title(\"training loss vs validation loss\")\nplt.show()\nplt.plot(t_f)\nplt.plot(v_f)\nplt.title(\"training f1 vs validation f1\")\nplt.show()\nplt.plot(t_a)\nplt.plot(v_a)\nplt.title(\"training acc vs validation acc\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"model path\"\nmodel.load_state_dict(torch.load(PATH))\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c,v = test_loop(test_dataloader, model, loss_fn, optimizer)\nprint(c,v)","metadata":{},"execution_count":null,"outputs":[]}]}